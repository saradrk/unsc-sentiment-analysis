TODO:
- speeches.tar entpacken
- Schreiben wie der Sentiment-Score berechnet wird
- Daten & zahlen 

Notes:

# make_lsd
- merges lsd and lsd neg
- saves meta info for entry pattern (nr of tokens and if its a prefix and the polarity)
- removes "unite*" and "united*" and "not (..both..)"  (which is a mistake anyway)
- 9152 entries processed
- 9144 entries result

# preprocess
- chose simple weils keinen gro√üen unterschied macht

# erst sentence annotation 
-  dabei wird annotation meta file erstellt

# dann speech annotation

Repo struktur:
- README.md
- config.py
- unsc_sentiment/
-- __init__.py
-- corpus_utils.py
-- lsd_utils.py
- data/
-- dataverse_files/
-- LSDaug2015/
##########
1. Repo clonen

2. virtual env installieren & aktivieren

2. a) requirements installieren ( + python -m spacy download en_core_web_sm ?)

3. Download Data

3 a. UNSC Data
- From: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/KGVSYH
- Download "Original Format ZIP"
- Unpack ZIP and move to this Repo (to data/ folder for order)

3 b. Lexicoder Data
- From: http://www.snsoroka.com/data-lexicoder/
- Download the Lexicoder Sentiment Dictionary
- Unpack ZIP and move to this Repo (to data/ folder for order)
- Unpack /extract speeches.tar

4. Usage

- adjust the paths to the files in config.py
- run make_lsd.py to process the LSD
- run make_sentence_annotations.py (dauert eube weile - aber 1x reucgt)
- run make_speech_annotations.py

